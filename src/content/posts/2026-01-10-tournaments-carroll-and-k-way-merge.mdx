---
title: "Tournaments, Lewis Carroll and efficient k-way merge"
date: 2026-01-10
tags: []
draft: false
---

Recently I watched the video below from Tigerbeetle developers, Tobias Ziegler (@toziegler) and Alex Kladov (@matklad), who walk through the Tree of Losers algorithm for k-way merge. The video focuses on how the algorithm is used in the

The joy of learning is finding yourself going down rabbit holes, just like Alice when she curiously followed a rabbit into his burrow and began all her adventures in Wonderland. In my case this video by Tigerbeetle developers  in which they walk through the Tree of Losers algorithm they used to speed up a merge process in their database.

<iframe width="560" height="315" src="https://www.youtube.com/embed/agjVihO6IPM?si=gBBtRn744A5A2Wqr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Tobias mentions that Knuth covers this topic extensively in vol3 of the Art of Computer Programming (Searching and Sorting), and so I scurried after the rabbit down the hole and this post is the result. I'll talk about the different algorithms used for k-way merge, why they are needed and where they are used, with some interative demos you can use to help fully understand the workings of these algorithns in an interative visual simulation. First though, let's talk about Tennis.

## Fairness in tennis tournaments

As Knuth brings up in section 5.3.3 - Minimum-Comparison Selection, in the aforementioned tome,

Rev. Charles Lutwidge Dodgson, better known by his pen name, Lewis Carroll, author of Alice's Adventures in Wonderland was also a mathematician and logician at Christ Church, Oxford, with a deep obsession for fairness in rules and voting systems.

## What links a tennis tournament with efficient database internals?

The joy of learning is that as soon as you dig into a topic you will find yourself going down unexpected rabbit holes and making unexpected connections. For example going down a rabbit hole comes from the Lewis Carroll book "Aliceâ€™s Adventures in Wonderland", in which Alice starts her adventure by following a rabbit into his burrow. In this post Lewis Carroll himself will make an appearance. The inspiration for this post was a great video from the TigerBeetle developers discussing how they recently sped up their k-way merge algorithm. You can watch here:

<iframe width="560" height="315" src="https://www.youtube.com/embed/agjVihO6IPM?si=gBBtRn744A5A2Wqr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

In this post I will tie together the connections between Lewis Carroll, k-way merging and the Tree of Losers algorithm.

## What is k-way merge

### Sorting by selection

<div style="text-align: center; margin: 20px 0;">
    <a href="https://heyes-jones.com/externalsort/linearscan.html" target="_blank" rel="noopener noreferrer" style="text-decoration: none;">
        <img src="../../../images/linear-scan-thumbnail.png" 
             alt="K-Way Merge Tree of Winners Visualization" 
             title="Click to launch interactive simulation"
             style="width: 100%; max-width: 800px; height: auto; border: 1px solid #444; border-radius: 8px; box-shadow: 0 4px 10px rgba(0,0,0,0.3);" />
        <p style="margin-top: 8px; color: #666; font-size: 0.9em;">
            ðŸ‘† <em>Click to try the interactive simulation</em>
        </p>
    </a>
</div>

To understand the use case and algorithms for k-way merge let's start with sorting by selection, which is where Knuth begins in section 5.23.

Selection sort works by finding the largest element in the array to be sorted and moving it to the end. You repeat this process again, and put the second largest element just before the last element. Repeating this until you reach the first element yields a fully sorted array. This is not a cheap sort though with runtimes of O(n^2) (best case even), but it does guarantee a maximum of n swaps. It is also unstable.

You can see Knuth's code here, converted to Python with the original MMIX code in the comments. [straightselectionsort.py](https://gist.github.com/justinhj/c609bbb630722dafe26d5023802b1693)

You could go to quick sort and other sorts with better runtime, but as we will see, sorting by selection has its uses so let's explore further.

Let's sort the following 9 numbers by selection. Each step is shown a separate row.

```org-table-temp 
|   8 |   4 |   3 |   7 |   5 | 2   | 9   | 1   | 6   |
|   8 |   4 |   3 |   7 |   5 | 2   | 6   | 1   | `9` |
|   1 |   4 |   3 |   7 |   5 | 2   | 6   | `8` | `9` |
|   1 |   4 |   3 |   6 |   5 | 2   | `7` | `8` | `9` |
|   1 |   4 |   3 |   2 |   5 | `6` | `7` | `8` | `9` |
|   1 |   2 |   3 |   4 | `5` | `6` | `7` | `8` | `9` |
|   1 |   2 |   3 | `4` | `5` | `6` | `7` | `8` | `9` |
|   1 |   2 | `3` | `4` | `5` | `6` | `7` | `8` | `9` |
|   1 | `2` | `3` | `4` | `5` | `6` | `7` | `8` | `9` |
| `1` | `2` | `3` | `4` | `5` | `6` | `7` | `8` | `9` |
```

In the above we make n-1 comparisons at the first step to be sure of the maximum. We keep track of the maximum found until we get to the beginning then swap the biggest one with the last one. In the next row we have one less comparison to do, and this continues reducing all the way to the last row.

Note that straight selection sort does not have a way to terminate early, so the numbers are sorted at the 6th step but we still execute all 9.

### Reducing comparisons

Quadratic selection (E H Friend, JACM 3, 1956) noted that instead of sorting the whole sequence at once you could divide into sqrt(n) groups.

```org-table-temp 
|   8 |   4 |   3 |   7 |   5 | 2   | 9   | 1   | 6   |
```

```org-table-temp 
| 8 | 4 | 3 |
| 7 | 5 | 2 |
| 9 | 1 | 6 |
```

Once you have the three groups find the largest in each.

```org-table-temp 
| `8` | 4 | 3 |
| `7` | 5 | 2 |
| `9` | 1 | 6 |
```

The largest elements is now the largest of the three "winners", 9.

To find the second largest, it could be either of the two remaining winners or one of the others in 9's group.

```org-table-temp 
| `8` | 4 |   3 |
| `7` | 5 |   2 |
| .   | 1 | `6` |
```

We find it is 8. So the next winner is the larger of 7, 6 or the others in 8's group.

```org-table-temp 
| .   | `4` |   3 |
| `7` | 5 |   2 |
| .   | 1 | `6` |
```

Proceeding this way the sort needs n sqrt n comparisons, much better than the original n^2.

Friend noted that you can continue this process of dividing the search into smaller groups based on the cubic root, the quartic, and ultimately into groups of two. Friend called this nth degree selecting. Knuth calls it tree selection.

### Tree Selection

Before Tree of Losers, which we will get to, there was the Tree of Winners

In Knuth we see the following diagram of a ping pong tournament. (section 5.2.3, Fig 22). Any sport works here really, the important thing is that when two people or teams compete the idea is that the best one will win. We will be dealing with sorting unchanging records so the analogy is not perfect. If Chris beats Pat on Sunday, he may still lose to Pat on Monday, but we can ignore that for the purposes of the algorithm.

                        Chris (Champion)
                            |
                +-----------+-----------+
                |                       |
              Chris                    Pat
                |                       |
          +-----+-----+           +-----+-----+
          |           |           |           |
         Kim        Chris        Pat        Robin
          |           |           |           |
       +--+--+     +--+--+     +--+--+     +--+--+
       |     |     |     |     |     |     |     |
      Kim  Sandy Chris  Lou   Pat   Ray   Dale Robin

The result of a tournament can be thought of as a binary tree where the winner is at the root. The two children will be the two players that played the final, and so on. It is clear we can go down the tree starting at Chris and say that he was better than each of his opponents; Pat, Kim and Lou.

The best player then, is Chris. But what if Chris had not shown up that day? Is Pat the best player?

Well all we know is that Pat beat all the opponents on her side of the tree, but we don't in fact know if she would have beaten the same opponents on Chris's side. So all we can say is that Chris was the best player overall, and Pat was the best player amongst the right subtree.

How can we find out the second best player? We need to play more games. Specifically. Lou should play Kim and Pat should play the winner of that game. Notice that "only two additional matches are required to find the second-best player, because of the structure we have remembered from the earlier games."

Tree selection, then, procedes by removing the winner of the tournament from our "Tree of Winners", then replaying the tournament without that player, and each replay requires lg N comparisons (log 2 N).

To make this more concrete as a sort lets change the players to their numeric values that determines who will win. We want to sort in ascending order so the lowest values win, and are output first.

Step 1 we remove 1 and output it as the first element.

    Sort output: 1
                        1 (Champion)
                            |
                +-----------+-----------+
                |                       |
                1                       3
                |                       |
          +-----+-----+           +-----+-----+
          |           |           |           |
          2           1           3           7
          |           |           |           |
       +--+--+     +--+--+     +--+--+     +--+--+
       |     |     |     |     |     |     |     |
       2     6     1     4     3     5     8     7

In step 2 we remove 1 from the tournament in preparation to replay without them.

    Sort output: 1,2
                            2 (Champion)
                            |
                +-----------+-----------+
                |                       |
                2                       3
                |                       |
          +-----+-----+           +-----+-----+
          |           |           |           |
          2           4           3           7
          |           |           |           |
       +--+--+     +--+--+     +--+--+     +--+--+
       |     |     |     |     |     |     |     |
       2     6     X     4     3     5     8     7

We started at the bottom of the tree, 4 has nobody to play so it moves up, 2 beats 4 and moves up, 2 beats 3 and becomes the new winner.

Now we remove 2. Replaying from the bottom gives the tree below and we output the 3.

    Sort output: 1,2,3
                            3 (Champion)
                            |
                +-----------+-----------+
                |                       |
                4                       3
                |                       |
          +-----+-----+           +-----+-----+
          |           |           |           |
          6           4           3           7
          |           |           |           |
       +--+--+     +--+--+     +--+--+     +--+--+
       |     |     |     |     |     |     |     |
       x     6     X     4     3     5     8     7

It's easy to see how this process can repeat until the tree is empty and we successfully completed our sort in n lg n time!

For greater clarity check out this visualization that creates random trees of data and lets you step through the process.

<div style="text-align: center; margin: 20px 0;">
    <a href="https://heyes-jones.com/externalsort/treeofwinners.html" target="_blank" rel="noopener noreferrer" style="text-decoration: none;">
        <img src="../../../images/tree-of-winners-thumbnail.png" 
             alt="K-Way Merge Tree of Winners Visualization" 
             title="Click to launch interactive simulation"
             style="width: 100%; max-width: 800px; height: auto; border: 1px solid #444; border-radius: 8px; box-shadow: 0 4px 10px rgba(0,0,0,0.3);" />
        <p style="margin-top: 8px; color: #666; font-size: 0.9em;">
            ðŸ‘† <em>Click to try the interactive simulation</em>
        </p>
    </a>
</div>

As you can see the selection tree algorithm works nicely, it gives us n lg k runtime instead. But that's not the end of the story, we can do better.

TODO There are some downsides this approach:

-   You must compare each sibling at each level, potential cache issue
-   Same work as with a heap but without the efficient storage

### min heap

The min-heap is often seen in applications, used as a priority queue, that is a queue where the elements are submitted in random order but can be retrieved efficiently in sorted order (smallest first, hence the name).

What's nice about a heap is it can be stored as an array in memory, with the tree flattened out. For example the following tree...

                            a
                            |
                +-----------+-----------+
                |                       |
                b                       c
                |                       |
          +-----+-----+           +-----+-----+
          |           |           |           |
          d           e           f           g

would be represented in the flat array...

```org-table-temp 
| a | b | c | d | e | f | g |
```

TODO advantages and disadvantages of the min-heap in general and in this use case.

We can use the min-heap to replace the tree selection method above, and it is often used for k-way merge applications. The heap has the size k (the number of merging streams) and you begin be initializing it with the first element in each stream.

Subsequently we can simply pop the next smallest element from the heap. Then we need a new one. Where do we get it? Similar to the selection tree method we must go to the stream where the winner came from. The reason for that is that when we initialized the tree, by defition we know that the winner was the smallest of all these elements. All we know now is the next smallest is either in the heap already, or it could be the next one in the winners stream.

You can play with this interactively here.

<div style="text-align: center; margin: 20px 0;">
    <a href="https://heyes-jones.com/externalsort/minheapmerge.html" target="_blank" rel="noopener noreferrer" style="text-decoration: none;">
        <img src="../../../images/min-heap-merge-thumbnail.png" 
             alt="K-Way Merge Tree of Losers Visualization" 
             title="Click to launch interactive simulation"
             style="width: 100%; max-width: 800px; height: auto; border: 1px solid #444; border-radius: 8px; box-shadow: 0 4px 10px rgba(0,0,0,0.3);" />
        <p style="margin-top: 8px; color: #666; font-size: 0.9em;">
            ðŸ‘† <em>Click to try the interactive simulation</em>
        </p>
    </a>
</div>

### Tree of Losers

<div style="text-align: center; margin: 20px 0;">
    <a href="https://heyes-jones.com/externalsort/treeoflosers.html" target="_blank" rel="noopener noreferrer" style="text-decoration: none;">
        <img src="../../../images/tree-of-losers-thumbnail.png" 
             alt="K-Way Merge Tree of Losers Visualization" 
             title="Click to launch interactive simulation"
             style="width: 100%; max-width: 800px; height: auto; border: 1px solid #444; border-radius: 8px; box-shadow: 0 4px 10px rgba(0,0,0,0.3);" />
        <p style="margin-top: 8px; color: #666; font-size: 0.9em;">
            ðŸ‘† <em>Click to try the interactive simulation</em>
        </p>
    </a>
</div>

## k-way merge in modern database architecture

In Knuth's In database architectures such as LSM (Log Structured Merge Trees) and Tigerbeetle's own custom architecture

## Tigerbeetle

how many streams do they merge

in scan_tree.zig the kway is initialised const streams_count = constants.lsm_levels + 2;_/_ The number of levels in an LSM tree._/_ A higher number of levels increases read amplification, as well as total storage capacity. pub const lsm_levels = config.cluster.lsm_levels; must fit in a u6 (max 64) lsm_levels: u6 = 7, (starts at 7 but does it increase)

## Tournaments

What does this have to do with Tennis tournaments? The above video prompted me to look into the relavent chapters in Knuth's "Art of Computer Programming vol3 - Searching and Sorting", where he describes the k-way merge problem following on from selection sort in general.

    A quote.

## Notes on kway merge to add above

### linear scan

k-1 minimum k n complexity good when small numbers of k zero overhead maybe vectorizable (simd AVX/NEON can compare 4/8 integers in a cpu cycle) does not scale to high values of k

has a visualization now!

### min-heap

uses k space pop the min element (log K) then add the next element from its stream, then heapify (log K) note we replace the top element and sift down rather than pop and push

sifting down requires two comparisons per level, left and right subtree, it goes top down large heap can be bad for the cache branch mispredictions

### Tree of Winners

This is where we start with the final tournament and all the winners at each level You take the champion then replay the tournament up from the champions leaf node

more natural representation but

you must compare each sibling at each level, potential cache issue same work as with a heap but without the efficient storage

### tree of losers

go from leaf upwards when doing replay you don't have to compare siblings only the next parent

half as many nodes to check compared to winner tree fixed path, better prediction

a bit more complexity (storing the offset logic)

### comparison count notes

tree of winners AND loser both take the same number of comparisons no matter the seed min heap is somewhat variable based on the number of sift down steps needed linear scan is variable based on the streams emptying

Thanks for reading!

\\copy2026 Justin Heyes-Jones. All Rights Reserved
